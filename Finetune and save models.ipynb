{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/giorginolab/protein_bert/blob/master/ProteinBERT_Toni.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WuzrtoTNf85y"
   },
   "source": [
    "# ProteinBERT demo\n",
    "\n",
    "This uses the model and weights provided by\n",
    "\n",
    "> Brandes N, Ofer D, Peleg Y, Rappoport N, Linial M. ProteinBERT: A universal deep-learning model of protein sequence and function. bioRxiv. 2021 May 25;2021.05.24.445464.  https://www.biorxiv.org/content/10.1101/2021.05.24.445464v1 \n",
    "\n",
    "Code based on the repository, https://github.com/nadavbra/protein_bert . \n",
    "\n",
    "Adapted for Google Colab by Toni Giorgino, www.giorginolab.it .\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wrMHtocjDOk4"
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zRbTekgkLXfr",
    "outputId": "2dafbbde-d6c9-4452-bab0-3f309b7c1c5e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 3749876317132647526\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 7744061440\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "    link {\n",
      "      device_id: 1\n",
      "      type: \"StreamExecutor\"\n",
      "      strength: 1\n",
      "    }\n",
      "  }\n",
      "}\n",
      "incarnation: 7242276252769984084\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 1080, pci bus id: 0000:02:00.0, compute capability: 6.1\"\n",
      ", name: \"/device:GPU:1\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 7744061440\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "    link {\n",
      "      type: \"StreamExecutor\"\n",
      "      strength: 1\n",
      "    }\n",
      "  }\n",
      "}\n",
      "incarnation: 8218700750548764620\n",
      "physical_device_desc: \"device: 1, name: GeForce GTX 1080, pci bus id: 0000:03:00.0, compute capability: 6.1\"\n",
      "]\n",
      "Wed Jul 14 15:19:50 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 450.102.04   Driver Version: 450.102.04   CUDA Version: 11.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce GTX 680     On   | 00000000:01:00.0 N/A |                  N/A |\n",
      "| 35%   57C    P0    N/A /  N/A |     96MiB /  1996MiB |     N/A      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  GeForce GTX 1080    On   | 00000000:02:00.0 Off |                  N/A |\n",
      "| 60%   65C    P2    49W / 180W |    234MiB /  8119MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  GeForce GTX 1080    On   | 00000000:03:00.0 Off |                  N/A |\n",
      "|  7%   53C    P2    40W / 180W |    234MiB /  8119MiB |      8%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    1   N/A  N/A     29181      C   ...vs/proteinbert/bin/python      225MiB |\n",
      "|    2   N/A  N/A     29181      C   ...vs/proteinbert/bin/python      225MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MNvfPHcSLXqv",
    "outputId": "8b057f32-3ef2-45e9-cbfd-ab5bd4d2294e"
   },
   "outputs": [],
   "source": [
    "# The examples in this notebook use a set of nine benchmarks described in the publication.\n",
    "# These benchmarks can be downloaded via FTP from: ftp.cs.huji.ac.il/users/nadavb/protein_bert/protein_benchmarks\n",
    "# Download the benchmarks into a directory on your machine and set the following variable to the path of that directory.\n",
    "import os\n",
    "BENCHMARKS_DIR = os.path.join(os.getcwd(), \"protein_benchmarks\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4hDTRkIEDOlG"
   },
   "source": [
    "# Fine-tune the model for the signal peptide benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wGofZ4oLDOlM"
   },
   "source": [
    "# Run all benchmarks\n",
    "\n",
    "Do not run - takes too much time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7-aAqCNiDOlP",
    "outputId": "fa554278-da22-4005-c61f-9e7dd51a5326"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2021_07_14-15:20:00] ========== signalP_binary ==========\n",
      "[2021_07_14-15:20:00] Output type: global binary\n",
      "[2021_07_14-15:20:00] Validation set /home/toni/work/protein_bert/protein_benchmarks/signalP_binary.valid.csv missing. Splitting training set instead.\n",
      "[2021_07_14-15:20:00] 14945 training set records, 1661 validation set records, 4152 test set records.\n",
      "[2021_07_14-15:20:00] Training set: Filtered out 0 of 14945 (0.0%) records of lengths exceeding 510.\n",
      "[2021_07_14-15:20:01] Validation set: Filtered out 0 of 1661 (0.0%) records of lengths exceeding 510.\n",
      "[2021_07_14-15:20:01] Training with frozen pretrained layers...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/toni/Apps/anaconda3/envs/proteinbert/lib/python3.9/site-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:374: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "468/468 [==============================] - 42s 72ms/step - loss: 0.0946 - val_loss: 0.0653\n",
      "Epoch 2/40\n",
      "468/468 [==============================] - 32s 68ms/step - loss: 0.0744 - val_loss: 0.0683\n",
      "\n",
      "Epoch 00002: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "Epoch 3/40\n",
      "468/468 [==============================] - 32s 68ms/step - loss: 0.0593 - val_loss: 0.0649\n",
      "Epoch 4/40\n",
      "468/468 [==============================] - 32s 68ms/step - loss: 0.0563 - val_loss: 0.0629\n",
      "Epoch 5/40\n",
      "468/468 [==============================] - 32s 68ms/step - loss: 0.0597 - val_loss: 0.0609\n",
      "Epoch 6/40\n",
      "468/468 [==============================] - 32s 68ms/step - loss: 0.0555 - val_loss: 0.0619\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "Epoch 7/40\n",
      "468/468 [==============================] - 32s 68ms/step - loss: 0.0507 - val_loss: 0.0616\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
      "[2021_07_14-15:23:59] Training the entire fine-tuned model...\n",
      "[2021_07_14-15:24:08] Incompatible number of optimizer weights - will not initialize them.\n",
      "Epoch 1/40\n",
      "468/468 [==============================] - 91s 180ms/step - loss: 0.0588 - val_loss: 0.0736\n",
      "Epoch 2/40\n",
      "468/468 [==============================] - 83s 177ms/step - loss: 0.0438 - val_loss: 0.0601\n",
      "Epoch 3/40\n",
      "468/468 [==============================] - 83s 178ms/step - loss: 0.0346 - val_loss: 0.0775\n",
      "\n",
      "Epoch 00003: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "Epoch 4/40\n",
      "468/468 [==============================] - 83s 178ms/step - loss: 0.0175 - val_loss: 0.0656\n",
      "\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "[2021_07_14-15:29:53] Training on final epochs of sequence length 1024...\n",
      "[2021_07_14-15:29:53] Training set: Filtered out 0 of 14945 (0.0%) records of lengths exceeding 1022.\n",
      "[2021_07_14-15:29:54] Validation set: Filtered out 0 of 1661 (0.0%) records of lengths exceeding 1022.\n",
      "935/935 [==============================] - 173s 178ms/step - loss: 0.0332 - val_loss: 0.0567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) input-seq, input-annotations with unsupported characters which will be renamed to input_seq, input_annotations in the SavedModel.\n",
      "/home/toni/Apps/anaconda3/envs/proteinbert/lib/python3.9/site-packages/tensorflow/python/keras/utils/generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: signalP_binary/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: signalP_binary/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2021_07_14-15:33:14] *** Training-set performance: ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/toni/Apps/anaconda3/envs/proteinbert/lib/python3.9/site-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:374: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th># records</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model seq len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>14945</td>\n",
       "      <td>0.99953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>14945</td>\n",
       "      <td>0.99953</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               # records      AUC\n",
       "Model seq len                    \n",
       "512                14945  0.99953\n",
       "All                14945  0.99953"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2021_07_14-15:33:46] Confusion matrix:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12440</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27</td>\n",
       "      <td>2401</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0     1\n",
       "0  12440    77\n",
       "1     27  2401"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2021_07_14-15:33:46] *** Validation-set performance: ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/toni/Apps/anaconda3/envs/proteinbert/lib/python3.9/site-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:374: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th># records</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model seq len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>1661</td>\n",
       "      <td>0.993242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>1661</td>\n",
       "      <td>0.993242</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               # records       AUC\n",
       "Model seq len                     \n",
       "512                 1661  0.993242\n",
       "All                 1661  0.993242"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2021_07_14-15:33:52] Confusion matrix:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1370</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>265</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0    1\n",
       "0  1370   21\n",
       "1     5  265"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2021_07_14-15:33:52] *** Test-set performance: ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/toni/Apps/anaconda3/envs/proteinbert/lib/python3.9/site-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:374: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th># records</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model seq len</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>4152</td>\n",
       "      <td>0.996204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>4152</td>\n",
       "      <td>0.996204</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               # records       AUC\n",
       "Model seq len                     \n",
       "512                 4152  0.996204\n",
       "All                 4152  0.996204"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2021_07_14-15:34:03] Confusion matrix:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3427</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24</td>\n",
       "      <td>650</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0    1\n",
       "0  3427   51\n",
       "1    24  650"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping - uncomment if you are sure\n",
      "[2021_07_14-15:34:03] ========== fluorescence ==========\n",
      "[2021_07_14-15:34:03] Output type: global numeric\n",
      "[2021_07_14-15:34:03] 21446 training set records, 5362 validation set records, 27217 test set records.\n",
      "[2021_07_14-15:34:03] Training set: Filtered out 0 of 21446 (0.0%) records of lengths exceeding 510.\n",
      "[2021_07_14-15:34:05] Validation set: Filtered out 0 of 5362 (0.0%) records of lengths exceeding 510.\n",
      "[2021_07_14-15:34:05] Training with frozen pretrained layers...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/toni/Apps/anaconda3/envs/proteinbert/lib/python3.9/site-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:374: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "671/671 [==============================] - 62s 81ms/step - loss: 0.7058 - val_loss: 0.5614\n",
      "Epoch 2/40\n",
      "671/671 [==============================] - 52s 77ms/step - loss: 0.6405 - val_loss: 0.5859\n",
      "\n",
      "Epoch 00002: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "Epoch 3/40\n",
      "671/671 [==============================] - 52s 77ms/step - loss: 0.5420 - val_loss: 0.4023\n",
      "Epoch 4/40\n",
      "671/671 [==============================] - 52s 77ms/step - loss: 0.5108 - val_loss: 0.4001\n",
      "Epoch 5/40\n",
      "671/671 [==============================] - 52s 77ms/step - loss: 0.5025 - val_loss: 0.3978\n",
      "Epoch 6/40\n",
      "671/671 [==============================] - 52s 77ms/step - loss: 0.4974 - val_loss: 0.3892\n",
      "Epoch 7/40\n",
      "671/671 [==============================] - 52s 77ms/step - loss: 0.4953 - val_loss: 0.4319\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "Epoch 8/40\n",
      "671/671 [==============================] - 52s 77ms/step - loss: 0.4779 - val_loss: 0.3845\n",
      "Epoch 9/40\n",
      "671/671 [==============================] - 52s 77ms/step - loss: 0.4686 - val_loss: 0.3839\n",
      "Epoch 10/40\n",
      "671/671 [==============================] - 52s 77ms/step - loss: 0.4637 - val_loss: 0.3841\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
      "Epoch 11/40\n",
      "671/671 [==============================] - 52s 77ms/step - loss: 0.4570 - val_loss: 0.3835\n",
      "Epoch 12/40\n",
      "671/671 [==============================] - 52s 77ms/step - loss: 0.4568 - val_loss: 0.3830\n",
      "Epoch 13/40\n",
      "671/671 [==============================] - 52s 77ms/step - loss: 0.4590 - val_loss: 0.3832\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 3.9062499126885086e-05.\n",
      "Epoch 14/40\n",
      "671/671 [==============================] - 52s 77ms/step - loss: 0.4575 - val_loss: 0.3826\n",
      "Epoch 15/40\n",
      "671/671 [==============================] - 52s 77ms/step - loss: 0.4577 - val_loss: 0.3830\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "Epoch 16/40\n",
      "671/671 [==============================] - 52s 77ms/step - loss: 0.4561 - val_loss: 0.3828\n",
      "[2021_07_14-15:48:09] Training the entire fine-tuned model...\n",
      "[2021_07_14-15:48:17] Incompatible number of optimizer weights - will not initialize them.\n",
      "Epoch 1/40\n",
      "671/671 [==============================] - 135s 191ms/step - loss: 0.4903 - val_loss: 0.3163\n",
      "Epoch 2/40\n",
      "671/671 [==============================] - 126s 188ms/step - loss: 0.4184 - val_loss: 0.3172\n",
      "\n",
      "Epoch 00002: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "Epoch 3/40\n",
      "671/671 [==============================] - 127s 189ms/step - loss: 0.3230 - val_loss: 0.2536\n",
      "Epoch 4/40\n",
      "671/671 [==============================] - 126s 188ms/step - loss: 0.3054 - val_loss: 0.2921\n",
      "\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "Epoch 5/40\n",
      "671/671 [==============================] - 127s 189ms/step - loss: 0.2812 - val_loss: 0.2245\n",
      "Epoch 6/40\n",
      "671/671 [==============================] - 126s 188ms/step - loss: 0.2724 - val_loss: 0.2214\n",
      "Epoch 7/40\n",
      "671/671 [==============================] - 127s 189ms/step - loss: 0.2680 - val_loss: 0.2218\n",
      "Epoch 8/40\n",
      "671/671 [==============================] - 126s 188ms/step - loss: 0.2582 - val_loss: 0.2506\n",
      "[2021_07_14-16:05:22] Training on final epochs of sequence length 1024...\n",
      "[2021_07_14-16:05:22] Training set: Filtered out 0 of 21446 (0.0%) records of lengths exceeding 1022.\n",
      "[2021_07_14-16:05:24] Validation set: Filtered out 0 of 5362 (0.0%) records of lengths exceeding 1022.\n",
      " 570/1341 [===========>..................] - ETA: 2:10 - loss: 0.3560"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from proteinbert import OutputType, OutputSpec, FinetuningModelGenerator, load_pretrained_model, finetune, evaluate_by_len, log\n",
    "from proteinbert.conv_and_global_attention_model import get_model_with_hidden_layers_as_outputs\n",
    "\n",
    "BENCHMARKS = [\n",
    "    # name, output_type\n",
    "    ('signalP_binary', OutputType(False, 'binary')),\n",
    "    ('fluorescence', OutputType(False, 'numeric')),\n",
    "    ('remote_homology', OutputType(False, 'categorical')),\n",
    "    ('stability', OutputType(False, 'numeric')),\n",
    "    ('scop', OutputType(False, 'categorical')),\n",
    "    ('secondary_structure', OutputType(True, 'categorical')),\n",
    "    ('disorder_secondary_structure', OutputType(True, 'binary')),\n",
    "    ('ProFET_NP_SP_Cleaved', OutputType(False, 'binary')),\n",
    "    ('PhosphositePTM', OutputType(True, 'binary')),\n",
    "]\n",
    "\n",
    "settings = {\n",
    "    'max_dataset_size': None,\n",
    "    'max_epochs_per_stage': 40,\n",
    "    'seq_len': 512,\n",
    "    'batch_size': 32,\n",
    "    'final_epoch_seq_len': 1024,\n",
    "    'initial_lr_with_frozen_pretrained_layers': 1e-02,\n",
    "    'initial_lr_with_all_layers': 1e-04,\n",
    "    'final_epoch_lr': 1e-05,\n",
    "    'dropout_rate': 0.5,\n",
    "    'training_callbacks': [\n",
    "        keras.callbacks.ReduceLROnPlateau(patience = 1, factor = 0.25, min_lr = 1e-05, verbose = 1),\n",
    "        keras.callbacks.EarlyStopping(patience = 2, restore_best_weights = True),\n",
    "    ],\n",
    "}\n",
    "\n",
    "####### Uncomment for debug mode\n",
    "# settings['max_dataset_size'] = 500\n",
    "# settings['max_epochs_per_stage'] = 1\n",
    "\n",
    "def run_benchmark(benchmark_name, pretraining_model_generator, input_encoder, pretraining_model_manipulation_function = None):\n",
    "    \n",
    "    log('========== %s ==========' % benchmark_name)  \n",
    "    \n",
    "    output_type = get_benchmark_output_type(benchmark_name)\n",
    "    log('Output type: %s' % output_type)\n",
    "    \n",
    "    train_set, valid_set, test_set = load_benchmark_dataset(benchmark_name)        \n",
    "    log(f'{len(train_set)} training set records, {len(valid_set)} validation set records, {len(test_set)} test set records.')\n",
    "    \n",
    "    if settings['max_dataset_size'] is not None:\n",
    "        log('Limiting the training, validation and test sets to %d records each.' % settings['max_dataset_size'])\n",
    "        train_set = train_set.sample(min(settings['max_dataset_size'], len(train_set)), random_state = 0)\n",
    "        valid_set = valid_set.sample(min(settings['max_dataset_size'], len(valid_set)), random_state = 0)\n",
    "        test_set = test_set.sample(min(settings['max_dataset_size'], len(test_set)), random_state = 0)\n",
    "    \n",
    "    if output_type.is_seq or output_type.is_categorical:\n",
    "        train_set['label'] = train_set['label'].astype(str)\n",
    "        valid_set['label'] = valid_set['label'].astype(str)\n",
    "        test_set['label'] = test_set['label'].astype(str)\n",
    "    else:\n",
    "        train_set['label'] = train_set['label'].astype(float)\n",
    "        valid_set['label'] = valid_set['label'].astype(float)\n",
    "        test_set['label'] = test_set['label'].astype(float)\n",
    "        \n",
    "    if output_type.is_categorical:\n",
    "        \n",
    "        if output_type.is_seq:\n",
    "            unique_labels = sorted(set.union(*train_set['label'].apply(set)) | set.union(*valid_set['label'].apply(set)) | \\\n",
    "                    set.union(*test_set['label'].apply(set)))\n",
    "        else:\n",
    "            unique_labels = sorted(set(train_set['label'].unique()) | set(valid_set['label'].unique()) | set(test_set['label'].unique()))\n",
    "            \n",
    "        log('%d unique lebels.' % len(unique_labels))\n",
    "    elif output_type.is_binary:\n",
    "        unique_labels = [0, 1]\n",
    "    else:\n",
    "        unique_labels = None\n",
    "        \n",
    "    output_spec = OutputSpec(output_type, unique_labels)\n",
    "    model_generator = FinetuningModelGenerator(pretraining_model_generator, output_spec, pretraining_model_manipulation_function = \\\n",
    "            pretraining_model_manipulation_function, dropout_rate = settings['dropout_rate'])\n",
    "    finetune(model_generator, input_encoder, output_spec, train_set['seq'], train_set['label'], valid_set['seq'], valid_set['label'], \\\n",
    "            seq_len = settings['seq_len'], batch_size = settings['batch_size'], max_epochs_per_stage = settings['max_epochs_per_stage'], \\\n",
    "            lr = settings['initial_lr_with_all_layers'], begin_with_frozen_pretrained_layers = True, lr_with_frozen_pretrained_layers = \\\n",
    "            settings['initial_lr_with_frozen_pretrained_layers'], n_final_epochs = 1, final_seq_len = settings['final_epoch_seq_len'], \\\n",
    "            final_lr = settings['final_epoch_lr'], callbacks = settings['training_callbacks'])\n",
    "    \n",
    "    finetuned_model = model_generator.create_model(settings['seq_len'])\n",
    "    finetuned_model.save(benchmark_name)\n",
    "    finetuned_model.save_weights(benchmark_name)\n",
    "    \n",
    "    for dataset_name, dataset in [('Training-set', train_set), ('Validation-set', valid_set), ('Test-set', test_set)]:\n",
    "        \n",
    "        log('*** %s performance: ***' % dataset_name)\n",
    "        results, confusion_matrix = evaluate_by_len(model_generator, input_encoder, output_spec, dataset['seq'], dataset['label'], \\\n",
    "                start_seq_len = settings['seq_len'], start_batch_size = settings['batch_size'])\n",
    "    \n",
    "        with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "            display(results)\n",
    "        \n",
    "        if confusion_matrix is not None:\n",
    "            with pd.option_context('display.max_rows', 16, 'display.max_columns', 10):\n",
    "                log('Confusion matrix:')\n",
    "                display(confusion_matrix)\n",
    "                \n",
    "    return model_generator\n",
    "\n",
    "def load_benchmark_dataset(benchmark_name):\n",
    "    \n",
    "    train_set_file_path = os.path.join(BENCHMARKS_DIR, '%s.train.csv' % benchmark_name)\n",
    "    valid_set_file_path = os.path.join(BENCHMARKS_DIR, '%s.valid.csv' % benchmark_name)\n",
    "    test_set_file_path = os.path.join(BENCHMARKS_DIR, '%s.test.csv' % benchmark_name)\n",
    "    \n",
    "    train_set = pd.read_csv(train_set_file_path).dropna().drop_duplicates()\n",
    "    test_set = pd.read_csv(test_set_file_path).dropna().drop_duplicates()\n",
    "          \n",
    "    if os.path.exists(valid_set_file_path):\n",
    "        valid_set = pd.read_csv(valid_set_file_path).dropna().drop_duplicates()\n",
    "    else:\n",
    "        log(f'Validation set {valid_set_file_path} missing. Splitting training set instead.')\n",
    "        train_set, valid_set = train_test_split(train_set, stratify = train_set['label'], test_size = 0.1, random_state = 0)\n",
    "    \n",
    "    return train_set, valid_set, test_set\n",
    "\n",
    "def get_benchmark_output_type(benchmark_name):\n",
    "    for name, output_type in BENCHMARKS:\n",
    "        if name == benchmark_name:\n",
    "            return output_type\n",
    "        \n",
    "pretrained_model_generator, input_encoder = load_pretrained_model()\n",
    "\n",
    "for benchmark_name, _ in BENCHMARKS:\n",
    "    run_benchmark(benchmark_name, pretrained_model_generator, input_encoder, \n",
    "                  pretraining_model_manipulation_function = get_model_with_hidden_layers_as_outputs)\n",
    "    print(\"Skipping - uncomment if you are sure\")\n",
    "        \n",
    "log('Done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rYWZQbXTiqcs"
   },
   "source": [
    "# Predict an arbitrary sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vt6jjq0tioyi",
    "outputId": "5a89151c-54c1-4cef-c736-5d6d12d791fa"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.00042532]], dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_sequence = \"AAAAA\"\n",
    "my_seq_len = 512\n",
    "my_sequence_encoded = input_encoder.encode_X([my_sequence],my_seq_len)\n",
    "\n",
    "finetuned_model = model_generator.create_model(my_seq_len)\n",
    "finetuned_model.predict(my_sequence_encoded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jDeGybDcmff3",
    "outputId": "967b5e05-018e-4c57-8231-ccca3cadd68e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[23,  0,  0,  0,  0,  0, 24, 25, 25, 25, 25, 25, 25, 25, 25, 25,\n",
       "         25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25,\n",
       "         25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25,\n",
       "         25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25,\n",
       "         25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25,\n",
       "         25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25,\n",
       "         25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25,\n",
       "         25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25,\n",
       "         25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25,\n",
       "         25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25,\n",
       "         25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25,\n",
       "         25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25,\n",
       "         25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25,\n",
       "         25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25,\n",
       "         25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25,\n",
       "         25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25,\n",
       "         25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25,\n",
       "         25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25,\n",
       "         25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25,\n",
       "         25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25,\n",
       "         25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25,\n",
       "         25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25,\n",
       "         25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25,\n",
       "         25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25,\n",
       "         25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25,\n",
       "         25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25,\n",
       "         25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25,\n",
       "         25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25,\n",
       "         25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25,\n",
       "         25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25,\n",
       "         25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25,\n",
       "         25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25]],\n",
       "       dtype=int32), array([[0, 0, 0, ..., 0, 0, 0]], dtype=int8)]"
      ]
     },
     "execution_count": 32,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_sequence_encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9o2s8bpZDOlU"
   },
   "source": [
    "# Visualizing the attention layers\n",
    "\n",
    "You can run this only after you have fine-tuned the model on a benchmark (e.g. signal peptide) and obtained *model_generator*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V6oiHyMFoaiU",
    "outputId": "389f9eb2-ef76-4808-fc93-cbc2ae4f155f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) input-seq, input-annotations with unsupported characters which will be renamed to input_seq, input_annotations in the SavedModel.\n",
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  category=CustomMaskWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: finetuned/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: finetuned/assets\n"
     ]
    }
   ],
   "source": [
    "finetuned_model.save(\"finetuned\")\n",
    "finetuned_model.save_weights(\"finetuned_weights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "oBYl1M0ibU0d"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5EjiW3R4aqzd",
    "outputId": "fbb9a787-6990-4680-a808-23e602555ef5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 62568\n",
      "drwxr-xr-x 2 root root     4096 Jul 14 09:28  \u001b[0m\u001b[01;34mbin\u001b[0m/\n",
      "drwxr-xr-x 5 root root     4096 Jul 14 09:28  \u001b[01;34mbuild\u001b[0m/\n",
      "-rw-r--r-- 1 root root       91 Jul 14 10:12  checkpoint\n",
      "drwxr-xr-x 2 root root     4096 Jul 14 09:28  \u001b[01;34mdist\u001b[0m/\n",
      "drwxr-xr-x 4 root root     4096 Jul 14 10:12  \u001b[01;34mfinetuned\u001b[0m/\n",
      "-rw-r--r-- 1 root root 63994839 Jul 14 10:12  finetuned_weights.data-00000-of-00001\n",
      "-rw-r--r-- 1 root root     9163 Jul 14 10:12  finetuned_weights.index\n",
      "drwxr-xr-x 4 root root     4096 Jul 14 09:30  \u001b[01;34mproteinbert\u001b[0m/\n",
      "-rw-r--r-- 1 root root    18446 Jul 14 09:28 'ProteinBERT demo.ipynb'\n",
      "drwxr-xr-x 2 root root     4096 Jul 14 09:28  \u001b[01;34mprotein_bert.egg-info\u001b[0m/\n",
      "-rw-r--r-- 1 root root     7624 Jul 14 09:28  README.rst\n",
      "-rw-r--r-- 1 root root      711 Jul 14 09:28  setup.py\n"
     ]
    }
   ],
   "source": [
    "%ls -l "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jL9X2e_pa1xm"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "wrMHtocjDOk4",
    "wGofZ4oLDOlM"
   ],
   "include_colab_link": true,
   "name": "ProteinBERT Toni.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
